cs361

#### 1. Bias,variance, over-fit, under-fit

bias: How far your h(x) is from f(x)/ How far your hypothesis from each other.

variance: How far h1(x) is form h2(x) is from h3(x)â€¦It does not look at the f(x) at all/ How far away your hypothesis from each other.



underfitting: High bias, low variance

overfitting: Low bias, high variance



Increase overfitting:

1. Number of training instances goes down

2. Number of attributes goes up

3. Noise in the data goes up
4. Signal is more complex



Approaches to decrease overfitting:

1. Stop growing tree earlier
2. Post-prune the tree
3. Separate set of example(2/3 training, 1/3 validation)
4. Statistical test



What is the real cause of overfitting?

The overfitting could cause by oversearching in the training set which cause model over-complex.

Also, the feature selection could be one of reason.

A certain features seems best on training set, but another set of features looks better on the test set.



#### 2. Error

What are the four sources of error?

1. Random variation in the selection of the test data:  Simple size if much smaller than true population which can't be represent true population and contains some bias.

2. Random variation in the selection of the training data:  Simple size if much smaller than true population which can't be represent true population and contains some bias.
3. Randomness in the learning algorithm (e.g. initial weights): Randomness may cause model been trained badly random by chance.
4. Random classification error: There is error in data which caused by human.



How  can we minimized these error?



#### 3. Ensemble

###### Why do emsembles really work?

1. Statistical - Training data might not be sufficient which cause many  equally good hypothesis on the amount of data we have seen. Ensembles can average their votes and reduce the risk of choosing wrong classifier.

   

2. Computational - Many algorithm may stuck in local minima. Ensemble construct local search from many different starting points in H may provide better approximation of the true hypothesis.

   

3. Representational - Hypothesis space may not combine the true function. Through ensembles, the true hypothesis may be represented by a group of classifier.

###### What two things must be true for an ensemble to improve results?

1. Every classifier have to disagree with each other.
2. Every classifier have to be better than random.